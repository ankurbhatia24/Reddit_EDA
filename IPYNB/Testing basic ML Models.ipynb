{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = [\"AskIndia\", \"Coronavirus\", \"Non-Political\", \"Scheduled\", \"Photography\", \"Science/Technology\",\n",
    "          \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>over_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>4 days ago we had pending orders of 100 millio...</td>\n",
       "      <td>97</td>\n",
       "      <td>fwjdqr</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fwjdqr...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.586290e+09</td>\n",
       "      <td>&gt; We are getting frantic calls from our pharma...</td>\n",
       "      <td>india_ko_vanakkam</td>\n",
       "      <td>Modi has Stockholm syndrome To be fair, the e...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Randians who were big time users of dating app...</td>\n",
       "      <td>19</td>\n",
       "      <td>fizkkk</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fizkkk...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.584298e+09</td>\n",
       "      <td>I'd my own stint with these apps(a couple of m...</td>\n",
       "      <td>__knockknockturnal__</td>\n",
       "      <td>Someone matched with me just to tell me that ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     flair                                              title  \\\n",
       "0           0  AskIndia  4 days ago we had pending orders of 100 millio...   \n",
       "1           1  AskIndia  Randians who were big time users of dating app...   \n",
       "\n",
       "   score      id                                                url  \\\n",
       "0     97  fwjdqr  https://www.reddit.com/r/india/comments/fwjdqr...   \n",
       "1     19  fizkkk  https://www.reddit.com/r/india/comments/fizkkk...   \n",
       "\n",
       "   comms_num       created                                               body  \\\n",
       "0          6  1.586290e+09  > We are getting frantic calls from our pharma...   \n",
       "1         19  1.584298e+09  I'd my own stint with these apps(a couple of m...   \n",
       "\n",
       "                 author                                           comments  \\\n",
       "0     india_ko_vanakkam   Modi has Stockholm syndrome To be fair, the e...   \n",
       "1  __knockknockturnal__   Someone matched with me just to tell me that ...   \n",
       "\n",
       "   over_18  \n",
       "0    False  \n",
       "1    False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Flair_data.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flairs of \"[R]eddiquette\" are less, so removing\n",
    "data = data[data[\"flair\"] != \"[R]eddiquette\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "def string_form(value):\n",
    "    return str(value)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the text in string\n",
    "data['title'] = data['title'].apply(string_form)\n",
    "data['body'] = data['body'].apply(string_form)\n",
    "data['comments'] = data['comments'].apply(string_form)\n",
    "\n",
    "#Clean Text\n",
    "data['title'] = data['title'].apply(clean_text)\n",
    "data['body'] = data['body'].apply(clean_text)\n",
    "data['comments'] = data['comments'].apply(clean_text)\n",
    "\n",
    "# feature_combine = data[\"title\"] + data[\"comments\"] + data[\"body\"]\n",
    "feature_combine_title_n_body = data[\"title\"] + data[\"body\"]\n",
    "# data = data.assign(feature_combine = feature_combine)\n",
    "data = data.assign(title_n_body = feature_combine_title_n_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticreg(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "                 ])\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svm(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    \n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "                 ])\n",
    "    sgd.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = sgd.predict(X_test)\n",
    "        \n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    nb = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                    ])\n",
    "    nb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "    print(\"Results of Naive Bayes Classifier\")\n",
    "    nb_classifier(X_train, X_test, y_train, y_test)\n",
    "    print(\"Results of Linear Support Vector Machine\")\n",
    "    linear_svm(X_train, X_test, y_train, y_test)\n",
    "    print(\"Results of Logistic Regression\")\n",
    "    logisticreg(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair Detection using Title as Feature\n",
      "Results of Naive Bayes Classifier\n",
      "accuracy 0.6626506024096386\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.88      0.97      0.92        60\n",
      "       Coronavirus       0.53      0.82      0.65        62\n",
      "     Non-Political       0.52      0.45      0.48        69\n",
      "         Scheduled       0.66      0.93      0.77        84\n",
      "       Photography       0.72      0.83      0.77        70\n",
      "Science/Technology       0.77      0.89      0.83        64\n",
      "          Politics       0.84      0.66      0.74        71\n",
      "  Business/Finance       0.49      0.42      0.46        66\n",
      "    Policy/Economy       0.63      0.56      0.59        84\n",
      "            Sports       0.58      0.52      0.55        62\n",
      "              Food       0.67      0.36      0.46        73\n",
      "               AMA       0.71      0.57      0.63        65\n",
      "\n",
      "          accuracy                           0.66       830\n",
      "         macro avg       0.67      0.66      0.65       830\n",
      "      weighted avg       0.66      0.66      0.65       830\n",
      "\n",
      "Results of Linear Support Vector Machine\n",
      "accuracy 0.689156626506024\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.89      0.98      0.94        60\n",
      "       Coronavirus       0.60      0.79      0.69        62\n",
      "     Non-Political       0.55      0.45      0.50        69\n",
      "         Scheduled       0.71      0.95      0.82        84\n",
      "       Photography       0.75      0.83      0.79        70\n",
      "Science/Technology       0.86      0.98      0.92        64\n",
      "          Politics       0.78      0.69      0.73        71\n",
      "  Business/Finance       0.49      0.45      0.47        66\n",
      "    Policy/Economy       0.68      0.62      0.65        84\n",
      "            Sports       0.60      0.55      0.57        62\n",
      "              Food       0.58      0.38      0.46        73\n",
      "               AMA       0.65      0.60      0.62        65\n",
      "\n",
      "          accuracy                           0.69       830\n",
      "         macro avg       0.68      0.69      0.68       830\n",
      "      weighted avg       0.68      0.69      0.68       830\n",
      "\n",
      "Results of Logistic Regression\n",
      "accuracy 0.689156626506024\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.93      0.93      0.93        60\n",
      "       Coronavirus       0.67      0.81      0.73        62\n",
      "     Non-Political       0.40      0.42      0.41        69\n",
      "         Scheduled       0.83      0.92      0.87        84\n",
      "       Photography       0.86      0.80      0.83        70\n",
      "Science/Technology       0.95      0.97      0.96        64\n",
      "          Politics       0.84      0.66      0.74        71\n",
      "  Business/Finance       0.38      0.39      0.39        66\n",
      "    Policy/Economy       0.62      0.68      0.65        84\n",
      "            Sports       0.54      0.60      0.57        62\n",
      "              Food       0.56      0.48      0.52        73\n",
      "               AMA       0.77      0.62      0.68        65\n",
      "\n",
      "          accuracy                           0.69       830\n",
      "         macro avg       0.70      0.69      0.69       830\n",
      "      weighted avg       0.70      0.69      0.69       830\n",
      "\n",
      "\n",
      "Flair Detection using Body as Feature\n",
      "\n",
      "Flair Detection using URL as Feature\n",
      "\n",
      "Flair Detection using Comments as Feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "cat = data.flair\n",
    "\n",
    "V = data.title_n_body\n",
    "W = data.comments\n",
    "X = data.title\n",
    "Y = data.body\n",
    "Z = data.url\n",
    "\n",
    "print(\"Flair Detection using Title as Feature\")\n",
    "train_test(X,cat)\n",
    "print(\"\\nFlair Detection using Body as Feature\")\n",
    "# train_test(Y,cat)\n",
    "print(\"\\nFlair Detection using URL as Feature\")\n",
    "# train_test(Z,cat)\n",
    "print(\"\\nFlair Detection using Comments as Feature\")\n",
    "# train_test(V,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
