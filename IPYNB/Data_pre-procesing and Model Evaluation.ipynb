{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import keras\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>over_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>4 days ago we had pending orders of 100 millio...</td>\n",
       "      <td>97</td>\n",
       "      <td>fwjdqr</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fwjdqr...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.586290e+09</td>\n",
       "      <td>&gt; We are getting frantic calls from our pharma...</td>\n",
       "      <td>india_ko_vanakkam</td>\n",
       "      <td>Modi has Stockholm syndrome To be fair, the e...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Randians who were big time users of dating app...</td>\n",
       "      <td>19</td>\n",
       "      <td>fizkkk</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fizkkk...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.584298e+09</td>\n",
       "      <td>I'd my own stint with these apps(a couple of m...</td>\n",
       "      <td>__knockknockturnal__</td>\n",
       "      <td>Someone matched with me just to tell me that ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     flair                                              title  \\\n",
       "0           0  AskIndia  4 days ago we had pending orders of 100 millio...   \n",
       "1           1  AskIndia  Randians who were big time users of dating app...   \n",
       "\n",
       "   score      id                                                url  \\\n",
       "0     97  fwjdqr  https://www.reddit.com/r/india/comments/fwjdqr...   \n",
       "1     19  fizkkk  https://www.reddit.com/r/india/comments/fizkkk...   \n",
       "\n",
       "   comms_num       created                                               body  \\\n",
       "0          6  1.586290e+09  > We are getting frantic calls from our pharma...   \n",
       "1         19  1.584298e+09  I'd my own stint with these apps(a couple of m...   \n",
       "\n",
       "                 author                                           comments  \\\n",
       "0     india_ko_vanakkam   Modi has Stockholm syndrome To be fair, the e...   \n",
       "1  __knockknockturnal__   Someone matched with me just to tell me that ...   \n",
       "\n",
       "   over_18  \n",
       "0    False  \n",
       "1    False  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data = pd.read_csv('Flair_data.csv')  #total points 2782\n",
    "topics_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics_data[\"flair\"] == 'AskIndia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "#count no of points of each flair\n",
    "flairs = [\"AskIndia\", \"Coronavirus\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\",\n",
    "          \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n",
    "flair_count = [(i, len(topics_data[topics_data[\"flair\"] == i])) for i in flairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.hist(topics_data.flair)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ('[R]eddiquette', 18) points are very less - so removing this flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('AskIndia', 232),\n",
       " ('Coronavirus', 249),\n",
       " ('Non-Political', 216),\n",
       " ('[R]eddiquette', 0),\n",
       " ('Scheduled', 234),\n",
       " ('Photography', 222),\n",
       " ('Science/Technology', 221),\n",
       " ('Politics', 249),\n",
       " ('Business/Finance', 233),\n",
       " ('Policy/Economy', 220),\n",
       " ('Sports', 232),\n",
       " ('Food', 244),\n",
       " ('AMA', 212)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data = topics_data[topics_data[\"flair\"] != \"[R]eddiquette\"]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.hist(topics_data.flair)\n",
    "plt.show()\n",
    "flair_count = [(i, len(topics_data[topics_data[\"flair\"] == i])) for i in flairs]\n",
    "flair_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>over_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, flair, title, score, id, url, comms_num, created, body, author, comments, over_18]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data[topics_data[\"over_18\"] == True] #None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0\n",
      "[deleted] 0\n",
      "[removed] 0\n"
     ]
    }
   ],
   "source": [
    "# Check for nan or deleted or removed \n",
    "empties = ['nan', '[deleted]', '[removed]']\n",
    "for empty in empties:\n",
    "    print(empty, len(topics_data[topics_data['body'] == empty]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_data['body'] = topics_data['body'].apply(lambda x: '' if x in empties else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0\n",
      "[deleted] 0\n",
      "[removed] 0\n"
     ]
    }
   ],
   "source": [
    "# Check for nan or deleted or removed \n",
    "empties = ['nan', '[deleted]', '[removed]']\n",
    "for empty in empties:\n",
    "    print(empty, len(topics_data[topics_data['body'] == empty]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "def string_form(value):\n",
    "    return str(value)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/bs4/__init__.py:282: UserWarning: \"https://youtu.be/kBvIqVr__C0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "#Convert the text in string\n",
    "topics_data['title'] = topics_data['title'].apply(string_form)\n",
    "topics_data['body'] = topics_data['body'].apply(string_form)\n",
    "topics_data['comments'] = topics_data['comments'].apply(string_form)\n",
    "\n",
    "#Clean Text\n",
    "topics_data['title'] = topics_data['title'].apply(clean_text)\n",
    "topics_data['body'] = topics_data['body'].apply(clean_text)\n",
    "topics_data['comments'] = topics_data['comments'].apply(clean_text)\n",
    "\n",
    "feature_combine = topics_data[\"title\"] + topics_data[\"comments\"] + topics_data[\"body\"]\n",
    "feature_combine_title_n_body = topics_data[\"title\"] + topics_data[\"body\"]\n",
    "topics_data = topics_data.assign(feature_combine = feature_combine)\n",
    "topics_data = topics_data.assign(title_n_body = feature_combine_title_n_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>over_18</th>\n",
       "      <th>feature_combine</th>\n",
       "      <th>title_n_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>4 days ago pending orders 100 million hydroxyc...</td>\n",
       "      <td>97</td>\n",
       "      <td>fwjdqr</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fwjdqr...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.586290e+09</td>\n",
       "      <td>getting frantic calls pharma customers delayed...</td>\n",
       "      <td>india_ko_vanakkam</td>\n",
       "      <td>modi stockholm syndrome fair evidence chloroqu...</td>\n",
       "      <td>False</td>\n",
       "      <td>4 days ago pending orders 100 million hydroxyc...</td>\n",
       "      <td>4 days ago pending orders 100 million hydroxyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>randians big time users dating apps like tinde...</td>\n",
       "      <td>19</td>\n",
       "      <td>fizkkk</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fizkkk...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.584298e+09</td>\n",
       "      <td>id stint apps couple months one point didnt fe...</td>\n",
       "      <td>__knockknockturnal__</td>\n",
       "      <td>someone matched tell im fat cat 1 general foll...</td>\n",
       "      <td>False</td>\n",
       "      <td>randians big time users dating apps like tinde...</td>\n",
       "      <td>randians big time users dating apps like tinde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>r india thinks flat earthers</td>\n",
       "      <td>7</td>\n",
       "      <td>f25vx0</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/f25vx0...</td>\n",
       "      <td>31</td>\n",
       "      <td>1.581441e+09</td>\n",
       "      <td>encountered foreigner ig says round earth hoax...</td>\n",
       "      <td>Dev1003</td>\n",
       "      <td>havent found indian yet believes earth flat de...</td>\n",
       "      <td>False</td>\n",
       "      <td>r india thinks flat earthershavent found india...</td>\n",
       "      <td>r india thinks flat earthersencountered foreig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>people left 9 5 jobs pursue career music art f...</td>\n",
       "      <td>45</td>\n",
       "      <td>dtvliq</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/dtvliq...</td>\n",
       "      <td>34</td>\n",
       "      <td>1.573333e+09</td>\n",
       "      <td>couldnt add askindia flair mobile browser</td>\n",
       "      <td>c0mrade34</td>\n",
       "      <td>engineer advertisement shoots since last 1year...</td>\n",
       "      <td>False</td>\n",
       "      <td>people left 9 5 jobs pursue career music art f...</td>\n",
       "      <td>people left 9 5 jobs pursue career music art f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>somebody want kill full family</td>\n",
       "      <td>91</td>\n",
       "      <td>b7pvwt</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/b7pvwt...</td>\n",
       "      <td>24</td>\n",
       "      <td>1.554080e+09</td>\n",
       "      <td>24hrs local police station register case dont ...</td>\n",
       "      <td>amitkumarthakur</td>\n",
       "      <td>calm downgo sp office town file grievance imme...</td>\n",
       "      <td>False</td>\n",
       "      <td>somebody want kill full familycalm downgo sp o...</td>\n",
       "      <td>somebody want kill full family24hrs local poli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     flair                                              title  \\\n",
       "0           0  AskIndia  4 days ago pending orders 100 million hydroxyc...   \n",
       "1           1  AskIndia  randians big time users dating apps like tinde...   \n",
       "2           2  AskIndia                       r india thinks flat earthers   \n",
       "3           3  AskIndia  people left 9 5 jobs pursue career music art f...   \n",
       "4           4  AskIndia                     somebody want kill full family   \n",
       "\n",
       "   score      id                                                url  \\\n",
       "0     97  fwjdqr  https://www.reddit.com/r/india/comments/fwjdqr...   \n",
       "1     19  fizkkk  https://www.reddit.com/r/india/comments/fizkkk...   \n",
       "2      7  f25vx0  https://www.reddit.com/r/india/comments/f25vx0...   \n",
       "3     45  dtvliq  https://www.reddit.com/r/india/comments/dtvliq...   \n",
       "4     91  b7pvwt  https://www.reddit.com/r/india/comments/b7pvwt...   \n",
       "\n",
       "   comms_num       created                                               body  \\\n",
       "0          6  1.586290e+09  getting frantic calls pharma customers delayed...   \n",
       "1         19  1.584298e+09  id stint apps couple months one point didnt fe...   \n",
       "2         31  1.581441e+09  encountered foreigner ig says round earth hoax...   \n",
       "3         34  1.573333e+09          couldnt add askindia flair mobile browser   \n",
       "4         24  1.554080e+09  24hrs local police station register case dont ...   \n",
       "\n",
       "                 author                                           comments  \\\n",
       "0     india_ko_vanakkam  modi stockholm syndrome fair evidence chloroqu...   \n",
       "1  __knockknockturnal__  someone matched tell im fat cat 1 general foll...   \n",
       "2               Dev1003  havent found indian yet believes earth flat de...   \n",
       "3             c0mrade34  engineer advertisement shoots since last 1year...   \n",
       "4       amitkumarthakur  calm downgo sp office town file grievance imme...   \n",
       "\n",
       "   over_18                                    feature_combine  \\\n",
       "0    False  4 days ago pending orders 100 million hydroxyc...   \n",
       "1    False  randians big time users dating apps like tinde...   \n",
       "2    False  r india thinks flat earthershavent found india...   \n",
       "3    False  people left 9 5 jobs pursue career music art f...   \n",
       "4    False  somebody want kill full familycalm downgo sp o...   \n",
       "\n",
       "                                        title_n_body  \n",
       "0  4 days ago pending orders 100 million hydroxyc...  \n",
       "1  randians big time users dating apps like tinde...  \n",
       "2  r india thinks flat earthersencountered foreig...  \n",
       "3  people left 9 5 jobs pursue career music art f...  \n",
       "4  somebody want kill full family24hrs local poli...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title word count lengths: \n",
      " Min: 1 \n",
      " Max: 35 \n",
      " Average: 8.955499276410999\n",
      "Comments word count lengths: \n",
      " Min: 1 \n",
      " Max: 58215 \n",
      " Average: 326.089001447178\n",
      "Body word count lengths: \n",
      " Min: 1 \n",
      " Max: 3603 \n",
      " Average: 113.90159189580318\n",
      "Title n Body (combined) word count lengths: \n",
      " Min: 1 \n",
      " Max: 3620 \n",
      " Average: 121.85709117221418\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # average length of titles with min and max\n",
    "# # count the numbers of words in each title and calculate the min and max\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(221)\n",
    "title_word_lengths = [len(str(topics_data.title.iloc[i]).split(' ')) for i in range(len(topics_data))]\n",
    "max_title_word_length = max(title_word_lengths)\n",
    "min_title_word_length = min(title_word_lengths)\n",
    "average_title_word_length = sum(title_word_lengths)/len(title_word_lengths)\n",
    "plt.hist(title_word_lengths, bins = 30)\n",
    "\n",
    "plt.subplot(222)\n",
    "# average length of comments with min and max\n",
    "comments_word_lengths = [len(str(topics_data.comments.iloc[i]).split(' ')) for i in range(len(topics_data))]\n",
    "max_comments_word_length = max(comments_word_lengths)\n",
    "min_comments_word_length = min(comments_word_lengths)\n",
    "average_comments_word_length = sum(comments_word_lengths)/len(comments_word_lengths)\n",
    "plt.hist(comments_word_lengths, bins = 35, range=[0, 1000], align='mid')\n",
    "\n",
    "plt.subplot(223)\n",
    "# #average length of body with min and max\n",
    "body_word_lengths = [len(str(topics_data.body.iloc[i]).split(' ')) for i in range(len(topics_data))]\n",
    "max_body_word_length = max(body_word_lengths)\n",
    "min_body_word_length = min(body_word_lengths)\n",
    "average_body_word_length = sum(body_word_lengths)/len(body_word_lengths)\n",
    "plt.hist(body_word_lengths, bins = 30)\n",
    "\n",
    "plt.subplot(224)\n",
    "#average length of title and body combined with min and max\n",
    "tnb_word_lengths = [len(str(topics_data.title_n_body.iloc[i]).split(' ')) for i in range(len(topics_data))]\n",
    "max_tnb_word_length = max(tnb_word_lengths)\n",
    "min_tnb_word_length = min(tnb_word_lengths)\n",
    "average_tnb_word_length = sum(tnb_word_lengths)/len(tnb_word_lengths)\n",
    "plt.hist(tnb_word_lengths, bins = 30)\n",
    "\n",
    "print('Title word count lengths: \\n Min: {} \\n Max: {} \\n Average: {}'.format(min_title_word_length, max_title_word_length, average_title_word_length))\n",
    "print('Comments word count lengths: \\n Min: {} \\n Max: {} \\n Average: {}'.format(min_comments_word_length, max_comments_word_length, average_comments_word_length))\n",
    "print('Body word count lengths: \\n Min: {} \\n Max: {} \\n Average: {}'.format(min_body_word_length, max_body_word_length, average_body_word_length))\n",
    "print('Title n Body (combined) word count lengths: \\n Min: {} \\n Max: {} \\n Average: {}'.format(min_tnb_word_length, max_tnb_word_length, average_tnb_word_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS =  200000  #Max unique words that can be in a <text_type> (Comments, Body, Title)\n",
    "#From the above plots we can decide the max length of title, comments, body to consider\n",
    "#We keep in mind, not to make those the title word to vec arrays much sparse\n",
    "#Cropping of text from comments/body after a certain length will not make much loss\n",
    "MAX_TITLE_LENGTH =  20      #The average lenth of title is 9 words. And maximum is 35, so we can use \n",
    "                            #around 20 words in the title, and remove/pad\n",
    "                            #the remaining word spaces\n",
    "MAX_COMMENTS_LENGTH = 200\n",
    "MAX_BODY_LENGTH = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Glove Embeddings kept in my local Harddisk.\n",
    "## It can be Downloaded from here https://nlp.stanford.edu/projects/glove/\n",
    "## Large file - so cant upload in github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle of glove embeddings\n",
    "EMBEDDING_DIM = 300 #300d glove embeddings\n",
    "embedding_index_glove_300d = open(\"/media/ankur/05328ADB2605E075/MIDAS-MELD-DATASET/MELD.Raw/dev/\" + \n",
    "                                  \"dev_text_embedding_index_glove_300d.pickle\",\"rb\")\n",
    "text_embedding_index_glove_300d = pickle.load(embedding_index_glove_300d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning algorithms cannot work with raw text directly. Rather, the text must be converted into vectors of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code cell takes the text data and converts into word to vector \n",
    "## 1. Loads the Glove embedding\n",
    "## 2. Makes the dictionary from the words available in text.\n",
    "## 3. Find out the words in text already present in glove.\n",
    "## 4. Replaces the word with 300 dimensional word vector.\n",
    "## These embeddings (glove) are very well trained embeddings on huge corpus of text.\n",
    "## The words of similar types have larger correlation i.e. for example\n",
    "## the feature vectors of mango and apple will be similar in terms of class fruit.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_matrix(text, max_sequence_length, text_type, pickle_tokenizer):\n",
    "    #Make sure glove embedding is loaded in text_embedding_index_glove_300d\n",
    "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    \n",
    "    if(pickle_tokenizer):\n",
    "        pickle_tokenizer = open(f\"{text_type}_tokenizer.pickle\",\"wb\")\n",
    "        pickle.dump(tokenizer, pickle_tokenizer)\n",
    "        pickle_tokenizer.close()    \n",
    "        \n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found {} unique tokens. of {}'.format(len(word_index), text_type))\n",
    "    #Create embedding_matrix\n",
    "    num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "    embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "    words_not_in_glove = []\n",
    "    for word, i in word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = text_embedding_index_glove_300d.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            #the words not found are stored here\n",
    "            words_not_in_glove.append((word, i))\n",
    "    print(\"Shape of embedding matrix of {} type is {}\".format(text_type, embedding_matrix.shape))\n",
    "    #Pickle embedding_matrix (save embedding matrix for <text_type>)\n",
    "#     pickle_embedding_matrix = open(f\"{text_type}_embedding_matrix.pickle\",\"wb\")\n",
    "#     pickle.dump(embedding_matrix, pickle_embedding_matrix)\n",
    "#     pickle_embedding_matrix.close()\n",
    "    print(f\"Out of {len(word_index)} words, {len(words_not_in_glove)} words are not in glove embeddings\")\n",
    "    return ({\"tokenizer\" : tokenizer, \n",
    "             \"padded_sequences\" : padded_sequences,\n",
    "             \"max_sequence_length\" : max_sequence_length,\n",
    "             \"words_not_in_glove\" : words_not_in_glove, \n",
    "             \"embedding_matrix\" : embedding_matrix})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7357 unique tokens. of title\n",
      "Shape of embedding matrix of title type is (7358, 300)\n",
      "Out of 7357 words, 692 words are not in glove embeddings\n",
      "Found 37972 unique tokens. of body\n",
      "Shape of embedding matrix of body type is (37973, 300)\n",
      "Out of 37972 words, 15503 words are not in glove embeddings\n",
      "Found 41222 unique tokens. of body\n",
      "Shape of embedding matrix of body type is (41223, 300)\n",
      "Out of 41222 words, 17975 words are not in glove embeddings\n",
      "Found 96529 unique tokens. of body\n",
      "Shape of embedding matrix of body type is (96530, 300)\n",
      "Out of 96529 words, 56194 words are not in glove embeddings\n"
     ]
    }
   ],
   "source": [
    "title_encoded = make_embedding_matrix(topics_data.title, MAX_TITLE_LENGTH , 'title', pickle_tokenizer = 1)\n",
    "body_encoded = make_embedding_matrix(topics_data.body, MAX_BODY_LENGTH , 'body', pickle_tokenizer = 1)\n",
    "title_n_body_encoded = make_embedding_matrix(topics_data.title_n_body, MAX_TITLE_LENGTH + MAX_BODY_LENGTH , 'body', pickle_tokenizer = 1)\n",
    "title_n_body_n_comment_encoded = make_embedding_matrix(topics_data.feature_combine, MAX_TITLE_LENGTH + MAX_BODY_LENGTH + MAX_COMMENTS_LENGTH, 'body', pickle_tokenizer = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make training Data\n",
    "#Converting Flair to One-Hot\n",
    "\n",
    "label_encode_dict = {'AskIndia': 0,\n",
    "                         'Coronavirus': 1,\n",
    "                         'Non-Political': 2,\n",
    "                         'Scheduled': 3,\n",
    "                         'Photography': 4,\n",
    "                         'Science/Technology': 5,\n",
    "                         'Politics': 6,\n",
    "                         'Business/Finance': 7,\n",
    "                         'Policy/Economy': 8,\n",
    "                         'Sports': 9,\n",
    "                         'Food': 10,\n",
    "                         'AMA': 11}\n",
    "\n",
    "# label_decode_dict = {v: k for k, v in label_encode_dict.items()}\n",
    "\n",
    "label_decode_dict = {0: 'AskIndia',\n",
    "                         1: 'Coronavirus',\n",
    "                         2: 'Non-Political',\n",
    "                         3: 'Scheduled',\n",
    "                         4: 'Photography',\n",
    "                         5: 'Science/Technology',\n",
    "                         6: 'Politics',\n",
    "                         7: 'Business/Finance',\n",
    "                         8: 'Policy/Economy',\n",
    "                         9: 'Sports',\n",
    "                         10: 'Food',\n",
    "                         11: 'AMA'}\n",
    "def label_encode(label):\n",
    "    return label_encode_dict.get(label)\n",
    "def label_decode(label_value):\n",
    "    return label_decode_dict.get(label_value)\n",
    "\n",
    "\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# Y = onehot_encoder.fit_transform(Y.reshape(-1, 1))\n",
    "#Decode using [label_decode(v) for v in Y.argmax(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Flairs to One Hot Encoding\n",
    "Y = topics_data[\"flair\"]\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(Y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "Y = onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To invert One Hot Encoding\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title = title_encoded[\"padded_sequences\"]\n",
    "X_body = body_encoded[\"padded_sequences\"]\n",
    "X_title_n_body = title_n_body_encoded[\"padded_sequences\"]\n",
    "X_title_n_body_n_comment = title_n_body_n_comment_encoded[\"padded_sequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 692 words not in glove from a total of 7358 words\n",
      "Body: 15503 words not in glove from a total of 37973 words\n",
      "title_n_body: 17975 words not in glove from a total of 41223 words\n",
      "title_n_body_n_comment: 56194 words not in glove from a total of 96530 words\n"
     ]
    }
   ],
   "source": [
    "print(\"Title: {} words not in glove from a total of {} words\".format( len(title_encoded[\"words_not_in_glove\"]), len(title_encoded[\"tokenizer\"].word_index) + 1))\n",
    "print(\"Body: {} words not in glove from a total of {} words\".format( len(body_encoded[\"words_not_in_glove\"]), len(body_encoded[\"tokenizer\"].word_index) + 1))\n",
    "print(\"title_n_body: {} words not in glove from a total of {} words\".format( len(title_n_body_encoded[\"words_not_in_glove\"]), len(title_n_body_encoded[\"tokenizer\"].word_index) + 1))\n",
    "print(\"title_n_body_n_comment: {} words not in glove from a total of {} words\".format( len(title_n_body_n_comment_encoded[\"words_not_in_glove\"]), len(title_n_body_n_comment_encoded[\"tokenizer\"].word_index) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twittercom', 59),\n",
       " ('covid19', 156),\n",
       " ('wwwredditcom', 214),\n",
       " ('articleshow', 444),\n",
       " ('wwwyoutubecom', 513),\n",
       " ('imgurcom', 727),\n",
       " ('youve', 765),\n",
       " ('aadhaar', 778),\n",
       " ('mobiletwittercom', 858),\n",
       " ('economictimesindiatimescom', 895),\n",
       " ('askindia', 897),\n",
       " ('iimgurcom', 905),\n",
       " ('shouldnt', 908),\n",
       " ('wwwthehinducom', 949),\n",
       " ('covid', 1122),\n",
       " ('aadhar', 1164),\n",
       " ('enwikipediaorg', 1196),\n",
       " ('wwwgooglecom', 1228),\n",
       " ('timesofindiaindiatimescom', 1277),\n",
       " ('indianexpresscom', 1365),\n",
       " ('techeconomictimesindiatimescom', 1380),\n",
       " ('theyll', 1399),\n",
       " ('indianews', 1426),\n",
       " ('npredditcom', 1482),\n",
       " ('itll', 1495),\n",
       " ('wwwndtvcom', 1497),\n",
       " ('bhakts', 1554),\n",
       " ('wwwlivemintcom', 1559),\n",
       " ('zomato', 1630),\n",
       " ('subreddit', 1761),\n",
       " ('wwwindiatodayin', 1770),\n",
       " ('demonetisation', 1771),\n",
       " ('theyve', 1773),\n",
       " ('githubcom', 1874),\n",
       " ('ettech', 1925),\n",
       " ('wwwnews18com', 2192),\n",
       " ('swiggy', 2193),\n",
       " ('flipkart', 2223),\n",
       " ('1html', 2256),\n",
       " ('techcirclevccirclecom', 2272),\n",
       " ('modiji', 2286),\n",
       " ('samacharbot2', 2295),\n",
       " ('bjps', 2368),\n",
       " ('hotstar', 2389),\n",
       " ('wouldve', 2413),\n",
       " ('tosallurocks', 2418),\n",
       " ('hunkdivine', 2419),\n",
       " ('bhakt', 2430),\n",
       " ('werent', 2442),\n",
       " ('wwwmedianamacom', 2585),\n",
       " ('wwwbusinessstandardcom', 2624),\n",
       " ('chutiya', 2693),\n",
       " ('blockchain', 2705),\n",
       " ('politicsandnation', 2722),\n",
       " ('scrollin', 2818),\n",
       " ('adblocker', 2828),\n",
       " ('wwwhindustantimescom', 2846),\n",
       " ('lmao', 2869),\n",
       " ('inc42com', 2895),\n",
       " ('economiccalendar', 2927),\n",
       " ('modmail', 2942),\n",
       " ('sronsortnewtall', 3006),\n",
       " ('ininvestingcom', 3007),\n",
       " ('upvote', 3123),\n",
       " ('idk', 3164),\n",
       " ('techcircle', 3180),\n",
       " ('questions1', 3183),\n",
       " ('paytm', 3218),\n",
       " ('itemscredits', 3279),\n",
       " ('tbh', 3309),\n",
       " ('wwwfirstpostcom', 3317),\n",
       " ('antinational', 3322),\n",
       " ('uturn', 3361),\n",
       " ('usr33', 3370),\n",
       " ('stickied', 3390),\n",
       " ('theyd', 3410),\n",
       " ('composeto2fr2findiasubjectanti', 3527),\n",
       " ('inc42', 3529),\n",
       " ('wwwthehindubusinesslinecom', 3561),\n",
       " ('news18', 3604),\n",
       " ('thewirein', 3665),\n",
       " ('uidai', 3730),\n",
       " ('redditors', 3886),\n",
       " ('tldr', 3896),\n",
       " ('housingcom', 4012),\n",
       " ('1drvms', 4080),\n",
       " ('nrcprotest', 4091),\n",
       " ('remindme', 4154),\n",
       " ('indiainvestments', 4178),\n",
       " ('downvoted', 4179),\n",
       " ('wwwamazonin', 4242),\n",
       " ('delhis', 4279),\n",
       " ('randians', 4301),\n",
       " ('downvote', 4324),\n",
       " ('shitting', 4382),\n",
       " ('threadrestrict', 4384),\n",
       " ('snapdeal', 4424),\n",
       " ('searchqweekly', 4466),\n",
       " ('interestingwant', 4467),\n",
       " ('hydroxychloroquine', 4469),\n",
       " ('ofcourse', 4482),\n",
       " ('covid19indiaorg', 4525),\n",
       " ('yourstorycom', 4543),\n",
       " ('sanghis', 4566),\n",
       " ('wwwdeccanheraldcom', 4600),\n",
       " ('wwwthenewsminutecom', 4602),\n",
       " ('wwwbbccom', 4608),\n",
       " ('everyones', 4615),\n",
       " ('masaan', 4633),\n",
       " ('medianama', 4634),\n",
       " ('flashfeed', 4637),\n",
       " ('wwwmoneycontrolcom', 4680),\n",
       " ('theprintin', 4695),\n",
       " ('wwwdnaindiacom', 4696),\n",
       " ('couldve', 4705),\n",
       " ('pubg', 4727),\n",
       " ('casteist', 4753),\n",
       " ('megathread', 4779),\n",
       " ('wwwnytimescom', 4782),\n",
       " ('wwwcovid19indiaorg', 4786),\n",
       " ('iitb', 4802),\n",
       " ('previewreddit', 4816),\n",
       " ('flaired', 4831),\n",
       " ('brexit', 4875),\n",
       " ('inreuterscom', 4880),\n",
       " ('covid19india', 4883),\n",
       " ('kulcha', 4942),\n",
       " ('wwwnewindianexpresscom', 4967),\n",
       " ('wwwtheguardiancom', 4984),\n",
       " ('deletednan', 5011),\n",
       " ('altnews', 5020),\n",
       " ('yourstory', 5021),\n",
       " ('itna', 5093),\n",
       " ('soundcloudcom', 5112),\n",
       " ('aayog', 5312),\n",
       " ('sarscov2', 5389),\n",
       " ('livemint', 5432),\n",
       " ('youw', 5478),\n",
       " ('shithole', 5500),\n",
       " ('reddiquette', 5503),\n",
       " ('eli5', 5515),\n",
       " ('shits', 5545),\n",
       " ('linknan', 5639),\n",
       " ('upvoted', 5653),\n",
       " ('enmwikipediaorg', 5667),\n",
       " ('wwwfinancialexpresscom', 5678),\n",
       " ('indiabusiness', 5705),\n",
       " ('drivegooglecom', 5712),\n",
       " ('chahiye', 5721),\n",
       " ('acche', 5751),\n",
       " ('bahut', 5758),\n",
       " ('redditor', 5799),\n",
       " ('anyones', 5857),\n",
       " ('impressiontrue', 5860),\n",
       " ('readmenan', 5906),\n",
       " ('dutee', 5915),\n",
       " ('worldnews', 5939),\n",
       " ('internetfreedomin', 5944),\n",
       " ('meconomictimescom', 5951),\n",
       " ('tiktok', 5985),\n",
       " ('pbstwimgcom', 5999),\n",
       " ('shitshow', 6024),\n",
       " ('hindumuslim', 6057),\n",
       " ('bhutans', 6070),\n",
       " ('narendramodi', 6073),\n",
       " ('wfh', 6112),\n",
       " ('otherstates', 6113),\n",
       " ('shouldve', 6150),\n",
       " ('mohfw', 6153),\n",
       " ('keralas', 6156),\n",
       " ('saidthe', 6170),\n",
       " ('sitharaman', 6192),\n",
       " ('wwwwhoint', 6195),\n",
       " ('antimuslim', 6214),\n",
       " ('nonveg', 6224),\n",
       " ('fadnavis', 6236),\n",
       " ('10year', 6238),\n",
       " ('vccircle', 6239),\n",
       " ('lekin', 6270),\n",
       " ('docsgooglecom', 6308),\n",
       " ('ppes', 6315),\n",
       " ('bigbasket', 6320),\n",
       " ('wwwreuterscom', 6327),\n",
       " ('newslaundry', 6346),\n",
       " ('sourceshareutm', 6364),\n",
       " ('economypolicy', 6372),\n",
       " ('wewigion', 6399),\n",
       " ('removednan', 6405),\n",
       " ('nehrus', 6406),\n",
       " ('articleseconomictimesindiatimescom', 6415),\n",
       " ('subreddits', 6455),\n",
       " ('afaik', 6470),\n",
       " ('jayega', 6494),\n",
       " ('freecharge', 6499),\n",
       " ('indexhtml', 6524),\n",
       " ('wwwmohfwgovin', 6532),\n",
       " ('apputm', 6565),\n",
       " ('clickbait', 6595),\n",
       " ('isros', 6610),\n",
       " ('audioboomcom', 6616),\n",
       " ('familys', 6629),\n",
       " ('imho', 6654),\n",
       " ('downvotes', 6655),\n",
       " ('mediumcom', 6660),\n",
       " ('shuru', 6722),\n",
       " ('gaand', 6726),\n",
       " ('currentaffairs', 6731),\n",
       " ('wwwbloombergcom', 6736),\n",
       " ('delhipolice', 6737),\n",
       " ('wwwbusinesstodayin', 6780),\n",
       " ('nehruvian', 6810),\n",
       " ('shigoto', 6834),\n",
       " ('staterun', 6836),\n",
       " ('icmrnicin', 6929),\n",
       " ('wwwlivelawin', 6935),\n",
       " ('suryawanshi', 6950),\n",
       " ('ireddit', 6984),\n",
       " ('copypasta', 7002),\n",
       " ('nyay', 7016),\n",
       " ('imgur', 7017),\n",
       " ('thatll', 7033),\n",
       " ('nextimportant', 7051),\n",
       " ('internetorg', 7052),\n",
       " ('nsfw', 7084),\n",
       " ('wholl', 7115),\n",
       " ('zerodha', 7116),\n",
       " ('pmcares', 7148),\n",
       " ('adityanath', 7157),\n",
       " ('aarogya', 7160),\n",
       " ('mitron', 7171),\n",
       " ('hadnt', 7176),\n",
       " ('myntra', 7189),\n",
       " ('congresss', 7223),\n",
       " ('vshaped', 7268),\n",
       " ('thisll', 7274),\n",
       " ('cleartax', 7278),\n",
       " ('movementslets', 7280),\n",
       " ('wpcontent', 7283),\n",
       " ('selfpost', 7301),\n",
       " ('jugaad', 7318),\n",
       " ('hyd', 7344),\n",
       " ('fking', 7347),\n",
       " ('mybmc', 7368),\n",
       " ('thaali', 7369),\n",
       " ('wapbusinessstandardcom', 7373),\n",
       " ('mysuru', 7383),\n",
       " ('statewise', 7387),\n",
       " ('iama', 7394),\n",
       " ('mediumandroid', 7419),\n",
       " ('karke', 7447),\n",
       " ('indiai', 7449),\n",
       " ('cringy', 7455),\n",
       " ('athiest', 7463),\n",
       " ('searchqrandom', 7513),\n",
       " ('shortterm', 7517),\n",
       " ('changelog', 7521),\n",
       " ('mediumweb2x', 7523),\n",
       " ('chutiyas', 7567),\n",
       " ('loweffort', 7569),\n",
       " ('firstpost', 7653),\n",
       " ('21day', 7660),\n",
       " ('wwwoutlookindiacom', 7661),\n",
       " ('liveblog', 7668),\n",
       " ('wwwfacebookcom', 7682),\n",
       " ('wwwworldometersinfo', 7695),\n",
       " ('chutiye', 7703),\n",
       " ('theek', 7707),\n",
       " ('streamablecom', 7720),\n",
       " ('mnrega', 7734),\n",
       " ('padh', 7764),\n",
       " ('wwwprsindiaorg', 7788),\n",
       " ('saala', 7792),\n",
       " ('discussionrestrict', 7810),\n",
       " ('hackerrank', 7813),\n",
       " ('byjus', 7827),\n",
       " ('ltcg', 7831),\n",
       " ('kumbhakaran', 7832),\n",
       " ('16lpm', 7853),\n",
       " ('downvoting', 7873),\n",
       " ('selfie', 7960),\n",
       " ('thisi', 7971),\n",
       " ('qzcom', 7974),\n",
       " ('lagta', 7982),\n",
       " ('gaumutra', 7989),\n",
       " ('karenge', 8025),\n",
       " ('itni', 8067),\n",
       " ('are1', 8084),\n",
       " ('upvotes', 8089),\n",
       " ('oldredditcom', 8093),\n",
       " ('fixthe', 8117),\n",
       " ('neverbefore', 8118),\n",
       " ('naww', 8119),\n",
       " ('rajthis', 8120),\n",
       " ('modishah', 8121),\n",
       " ('urjit', 8123),\n",
       " ('pepperfry', 8124),\n",
       " ('idfc', 8127),\n",
       " ('zerorating', 8130),\n",
       " ('tharoors', 8157),\n",
       " ('rindia', 8187),\n",
       " ('arogya', 8196),\n",
       " ('whove', 8243),\n",
       " ('bajao', 8260),\n",
       " ('todayhttps', 8279),\n",
       " ('aninewsup', 8286),\n",
       " ('sakte', 8314),\n",
       " ('whod', 8327),\n",
       " ('caravanmagazinein', 8336),\n",
       " ('stateowned', 8373),\n",
       " ('hindusim', 8401),\n",
       " ('antinationals', 8429),\n",
       " ('anticaa', 8433),\n",
       " ('201112', 8453),\n",
       " ('njdg', 8457),\n",
       " ('pakke', 8458),\n",
       " ('ripthis', 8480),\n",
       " ('cryptocurrency', 8485),\n",
       " ('billtrack', 8489),\n",
       " ('ama1', 8491),\n",
       " ('eq9r3q', 8492),\n",
       " ('vaitheeswaran', 8494),\n",
       " ('hcq', 8498),\n",
       " ('zyada', 8500),\n",
       " ('bakchodi', 8501),\n",
       " ('shitpost', 8507),\n",
       " ('offtopic', 8530),\n",
       " ('thishttps', 8569),\n",
       " ('udemy', 8571),\n",
       " ('waale', 8585),\n",
       " ('mumbais', 8611),\n",
       " ('grofers', 8612),\n",
       " ('cmomaharashtra', 8613),\n",
       " ('babus', 8623),\n",
       " ('editioncnncom', 8629),\n",
       " ('mtimesofindiacom', 8632),\n",
       " ('bhenchod', 8639),\n",
       " ('selfies', 8647),\n",
       " ('wwwtelegraphindiacom', 8651),\n",
       " ('jaate', 8659),\n",
       " ('gujju', 8685),\n",
       " ('modia', 8692),\n",
       " ('cmon', 8724),\n",
       " ('uske', 8726),\n",
       " ('5060', 8737),\n",
       " ('itthe', 8776),\n",
       " ('upar', 8782),\n",
       " ('wwwnewslaundrycom', 8784),\n",
       " ('cji', 8788),\n",
       " ('votebank', 8829),\n",
       " ('ambanis', 8835),\n",
       " ('indianewsindia', 8836),\n",
       " ('4ssi0u', 8844),\n",
       " ('obor', 8856),\n",
       " ('seriesa', 8858),\n",
       " ('automod', 8873),\n",
       " ('reddits', 8874),\n",
       " ('scoopwhoop', 8909),\n",
       " ('chaddichandan', 8923),\n",
       " ('chutiyapa', 8967),\n",
       " ('saidhttps', 9004),\n",
       " ('splitladoo', 9022),\n",
       " ('mudiji', 9030),\n",
       " ('samajh', 9045),\n",
       " ('covidindiasupportcom', 9047),\n",
       " ('honble', 9056),\n",
       " ('feku', 9060),\n",
       " ('wwwtribuneindiacom', 9071),\n",
       " ('humare', 9151),\n",
       " ('hahaha', 9160),\n",
       " ('yeaws', 9181),\n",
       " ('chandrayaan2', 9225),\n",
       " ('irnss', 9240),\n",
       " ('nonmuslim', 9244),\n",
       " ('thithi', 9264),\n",
       " ('4u2iwn', 9268),\n",
       " ('you1', 9272),\n",
       " ('lnrdt', 9276),\n",
       " ('maujpur', 9278),\n",
       " ('wwwbloombergquintcom', 9282),\n",
       " ('dhfl', 9284),\n",
       " ('profitndtvcom', 9290),\n",
       " ('kurash', 9295),\n",
       " ('riscv', 9296),\n",
       " ('needhi', 9321),\n",
       " ('askreddit', 9339),\n",
       " ('gurugram', 9371),\n",
       " ('bohot', 9372),\n",
       " ('tadipar', 9376),\n",
       " ('redmi', 9426),\n",
       " ('sadhguru', 9429),\n",
       " ('maharashtras', 9440),\n",
       " ('arvindkejriwal', 9442),\n",
       " ('arvindgunasekar', 9444),\n",
       " ('peoplei', 9452),\n",
       " ('indiatoday', 9458),\n",
       " ('dettol', 9468),\n",
       " ('saketgokhale', 9480),\n",
       " ('pradeshs', 9482),\n",
       " ('timesnow', 9484),\n",
       " ('wwwgooglecoin', 9497),\n",
       " ('gomutra', 9504),\n",
       " ('sourceshare', 9517),\n",
       " ('nirbhaya', 9533),\n",
       " ('bdutt', 9556),\n",
       " ('iffs', 9637),\n",
       " ('cryptocurrencies', 9655),\n",
       " ('bluedart', 9662),\n",
       " ('bcoz', 9668),\n",
       " ('indiathe', 9688),\n",
       " ('psbs', 9694),\n",
       " ('oneplus', 9704),\n",
       " ('wwwthequintcom', 9715),\n",
       " ('bschools', 9717),\n",
       " ('shivsena', 9723),\n",
       " ('delhiviolence', 9726),\n",
       " ('nbfc', 9729),\n",
       " ('yajnik', 9742),\n",
       " ('indianfootball', 9788),\n",
       " ('india1', 9814),\n",
       " ('discordgg', 9851),\n",
       " ('chawal', 9863),\n",
       " ('istpdf', 9884),\n",
       " ('sanitisers', 9886),\n",
       " ('twothirds', 9888),\n",
       " ('topstories', 9900),\n",
       " ('selfquarantine', 9906),\n",
       " ('yahan', 9915),\n",
       " ('pinarayi', 9920),\n",
       " ('phonepe', 9958),\n",
       " ('madarchod', 9961),\n",
       " ('wwwftcom', 9963),\n",
       " ('viewuspsharing', 9973),\n",
       " ('threadhttps', 9977),\n",
       " ('milega', 9983),\n",
       " ('immak02', 9986),\n",
       " ('chaddi', 9989),\n",
       " ('novelcoronavirus2019', 9996),\n",
       " ('kahenge', 10004),\n",
       " ('iitian', 10006),\n",
       " ('myoutubecom', 10016),\n",
       " ('chaiwala', 10047),\n",
       " ('batchmates', 10049),\n",
       " ('itwhat', 10060),\n",
       " ('religioni', 10082),\n",
       " ('univewse', 10111),\n",
       " ('opindia', 10134),\n",
       " ('igst', 10164),\n",
       " ('csgo', 10188),\n",
       " ('lifei', 10191),\n",
       " ('ecourt', 10197),\n",
       " ('ecourts', 10198),\n",
       " ('qnet', 10214),\n",
       " ('kalikho', 10215),\n",
       " ('shitposting', 10231),\n",
       " ('indiatodayintodayin', 10239),\n",
       " ('kejriwals', 10265),\n",
       " ('mustafabad', 10266),\n",
       " ('delhiriots', 10267),\n",
       " ('threadreaderappcom', 10268),\n",
       " ('dhonis', 10272),\n",
       " ('dextermilburn', 10276),\n",
       " ('acquisitionsgenerally', 10277),\n",
       " ('mcnamarahere', 10278),\n",
       " ('rajans', 10281),\n",
       " ('pitaji', 10289),\n",
       " ('sourcecontentofinterestutm', 10290),\n",
       " ('mediumtextutm', 10291),\n",
       " ('demonitization', 10310),\n",
       " ('thisalso', 10337),\n",
       " ('worldometers', 10354),\n",
       " ('etci', 10372),\n",
       " ('tatkal', 10384),\n",
       " ('egovernance', 10394),\n",
       " ('rajma', 10419),\n",
       " ('mumbaimirror', 10437),\n",
       " ('wifes', 10448),\n",
       " ('nowhttps', 10463),\n",
       " ('departmenthttps', 10481),\n",
       " ('article31041672ece', 10484),\n",
       " ('delhibased', 10497),\n",
       " ('coronaindia', 10511),\n",
       " ('unkill', 10516),\n",
       " ('taali', 10542),\n",
       " ('antichina', 10556),\n",
       " ('delhiites', 10615),\n",
       " ('dumbass', 10673),\n",
       " ('waise', 10677),\n",
       " ('wwwbusinessinsiderin', 10700),\n",
       " ('indianan', 10708),\n",
       " ('adhaar', 10715),\n",
       " ('industrys', 10721),\n",
       " ('redditcom', 10734),\n",
       " ('me1', 10736),\n",
       " ('upa2', 10752),\n",
       " ('jabong', 10754),\n",
       " ('taseers', 10776),\n",
       " ('khehar', 10783),\n",
       " ('uppercaste', 10785),\n",
       " ('wwwdeccanchroniclecom', 10787),\n",
       " ('incs', 10796),\n",
       " ('msmes', 10798),\n",
       " ('worldclass', 10837),\n",
       " ('sharmas', 10849),\n",
       " ('thepeopleofin', 10855),\n",
       " ('tahirhussainaap', 10857),\n",
       " ('adanis', 10862),\n",
       " ('pregst', 10868),\n",
       " ('weektuesday', 10874),\n",
       " ('unicorpse', 10875),\n",
       " ('crapicorn', 10876),\n",
       " ('campaigncppst', 10890),\n",
       " ('idhar', 10893),\n",
       " ('rathee', 10895),\n",
       " ('pliss', 10936),\n",
       " ('circlejerk', 10952),\n",
       " ('atheismindia', 10960),\n",
       " ('indiahttps', 10964),\n",
       " ('makemytrip', 10966),\n",
       " ('herei', 11003),\n",
       " ('incase', 11012),\n",
       " ('timei', 11014),\n",
       " ('worldometer', 11052),\n",
       " ('wwwnaturecom', 11055),\n",
       " ('coronavirushttps', 11057),\n",
       " ('bnodesk', 11079),\n",
       " ('upvoting', 11099),\n",
       " ('coronavirussrchashtag', 11106),\n",
       " ('itedit', 11107),\n",
       " ('mobikwik', 11109),\n",
       " ('kejri', 11121),\n",
       " ('waah', 11128),\n",
       " ('iammohit', 11154),\n",
       " ('thodi', 11194),\n",
       " ('coai', 11200),\n",
       " ('garibi', 11202),\n",
       " ('covidoutin', 11203),\n",
       " ('yojna', 11225),\n",
       " ('skyrim', 11252),\n",
       " ('caanrc', 11266),\n",
       " ('wwwimdbcom', 11268),\n",
       " ('thati', 11285),\n",
       " ('peopwe', 11318),\n",
       " ('nodejs', 11328),\n",
       " ('doggo', 11355),\n",
       " ('mhrdgovin', 11365),\n",
       " ('javadekar', 11376),\n",
       " ('todayspaper', 11381),\n",
       " ('bahot', 11397),\n",
       " ('201819', 11401),\n",
       " ('swachh', 11437),\n",
       " ('it2', 11444),\n",
       " ('imgetimgcom', 11466),\n",
       " ('kvpy', 11467),\n",
       " ('ivmpodcastscom', 11468),\n",
       " ('audiogyancom', 11470),\n",
       " ('wwwhackerrankcom', 11471),\n",
       " ('facebooks', 11472),\n",
       " ('antiindia', 11477),\n",
       " ('gvmc', 11481),\n",
       " ('refas', 11484),\n",
       " ('harshalbot', 11485),\n",
       " ('newsite', 11490),\n",
       " ('iima', 11491),\n",
       " ('procaa', 11500),\n",
       " ('delhiriots2020', 11501),\n",
       " ('tukde', 11505),\n",
       " ('dharna', 11506),\n",
       " ('iamai', 11507),\n",
       " ('msme', 11509),\n",
       " ('kohlis', 11513),\n",
       " ('oxeam3', 11514),\n",
       " ('fundingyou', 11530),\n",
       " ('keral', 11534),\n",
       " ('firestick', 11544),\n",
       " ('gaitondes', 11545),\n",
       " ('wwwwashingtonpostcom', 11574),\n",
       " ('nonindian', 11584),\n",
       " ('youi', 11586),\n",
       " ('selfposts', 11593),\n",
       " ('jaise', 11598),\n",
       " ('netneutrality', 11613),\n",
       " ('itif', 11617),\n",
       " ('redditindia', 11619),\n",
       " ('chaddis', 11621),\n",
       " ('mightve', 11637),\n",
       " ('nofap', 11638),\n",
       " ('modijis', 11645),\n",
       " ('champani', 11653),\n",
       " ('nonvegetarian', 11668),\n",
       " ('goibibo', 11672),\n",
       " ('gmailcom', 11674),\n",
       " ('batao', 11693),\n",
       " ('dmart', 11706),\n",
       " ('saahilmenghani', 11722),\n",
       " ('wwwaljazeeracom', 11729),\n",
       " ('maryashakil', 11735),\n",
       " ('mumbaimirrorindiatimescom', 11750),\n",
       " ('newsscroll', 11756),\n",
       " ('indiaspend', 11758),\n",
       " ('sanitiser', 11775),\n",
       " ('kerela', 11778),\n",
       " ('pmnrf', 11785),\n",
       " ('iitm', 11810),\n",
       " ('baare', 11819),\n",
       " ('khud', 11824),\n",
       " ('sakta', 11827),\n",
       " ('mustve', 11838),\n",
       " ('likh', 11854),\n",
       " ('therell', 11855),\n",
       " ('adviceforpublic', 11860),\n",
       " ('unkills', 11883),\n",
       " ('allindia', 11918),\n",
       " ('nonhindus', 11942),\n",
       " ('aayega', 11943),\n",
       " ('athiests', 11967),\n",
       " ('autplayed', 12027),\n",
       " ('northie', 12037),\n",
       " ('chalta', 12040),\n",
       " ('mazumdarshaw', 12067),\n",
       " ('navroz', 12072),\n",
       " ('jaldi', 12075),\n",
       " ('gtfo', 12103),\n",
       " ('indiankanoonorg', 12135),\n",
       " ('scripbox', 12156),\n",
       " ('pastebincom', 12158),\n",
       " ('hnis', 12196),\n",
       " ('mimgurcom', 12203),\n",
       " ('apun', 12206),\n",
       " ('saveourprivacy', 12211),\n",
       " ('this3', 12215),\n",
       " ('5n3f8s', 12225),\n",
       " ('1012017', 12226),\n",
       " ('tweetposter', 12231),\n",
       " ('univs', 12232),\n",
       " ('indiaothers', 12235),\n",
       " ('iist', 12236),\n",
       " ('newsians', 12240),\n",
       " ('wwwaudiomaticin', 12256),\n",
       " ('iitians', 12265),\n",
       " ('iiser', 12266),\n",
       " ('wwwdailyoin', 12268),\n",
       " ('iust', 12275),\n",
       " ('201617', 12278),\n",
       " ('newspaper3k', 12280),\n",
       " ('codelucas', 12281),\n",
       " ('thegovernment', 12282),\n",
       " ('trais', 12284),\n",
       " ('pibnicin', 12291),\n",
       " ('doval', 12301),\n",
       " ('wwwaltnewsin', 12304),\n",
       " ('delhiburning', 12305),\n",
       " ('hatao', 12313),\n",
       " ('shaktikanta', 12316),\n",
       " ('byst', 12328),\n",
       " ('fy17', 12329),\n",
       " ('nagal', 12342),\n",
       " ('vredditdownloader', 12343),\n",
       " ('jinson', 12350),\n",
       " ('motwane', 12353),\n",
       " ('bikerni', 12354),\n",
       " ('nonpersonal', 12422),\n",
       " ('intercaste', 12434),\n",
       " ('thik', 12437),\n",
       " ('italso', 12440),\n",
       " ('itthis', 12447),\n",
       " ('india2', 12458),\n",
       " ('mallyas', 12459),\n",
       " ('neend', 12483),\n",
       " ('cultfit', 12496),\n",
       " ('chromecast', 12526),\n",
       " ('pornhub', 12532),\n",
       " ('beela', 12534),\n",
       " ('sardesairajdeep', 12536),\n",
       " ('dhanyarajendran', 12538),\n",
       " ('amnestyorgin', 12543),\n",
       " ('supportindiasmostvulnerablefightcovid19alistoffundraisersyoucandonateto',\n",
       "  12544),\n",
       " ('poora', 12547),\n",
       " ('bolne', 12548),\n",
       " ('gujarats', 12549),\n",
       " ('covid19https', 12560),\n",
       " ('thalis', 12562),\n",
       " ('dayshttps', 12568),\n",
       " ('aajtak', 12570),\n",
       " ('wwwbbccouk', 12571),\n",
       " ('tshirt', 12579),\n",
       " ('sabko', 12584),\n",
       " ('mereko', 12591),\n",
       " ('wwwtheweekin', 12597),\n",
       " ('dillidurast', 12600),\n",
       " ('utha', 12604),\n",
       " ('caseshttps', 12608),\n",
       " ('techcrunchcom', 12615),\n",
       " ('inko', 12638),\n",
       " ('prolly', 12644),\n",
       " ('bolna', 12652),\n",
       " ('delhinews', 12653),\n",
       " ('alcoholbased', 12656),\n",
       " ('ppccbba', 12665),\n",
       " ('waali', 12667),\n",
       " ('1cr', 12670),\n",
       " ('covid2019', 12676),\n",
       " ('khelo', 12710),\n",
       " ('indexphp', 12714),\n",
       " ('imsodone', 12715),\n",
       " ('ppatra', 12716),\n",
       " ('nowi', 12723),\n",
       " ('sadhvi', 12738),\n",
       " ('shankh', 12744),\n",
       " ('mutra', 12750),\n",
       " ('zeenewsindiacom', 12756),\n",
       " ('baahubali', 12774),\n",
       " ('sabka', 12824),\n",
       " ('kitne', 12829),\n",
       " ('bolta', 12830),\n",
       " ('cringey', 12849),\n",
       " ('itbut', 12862),\n",
       " ('antireligion', 12872),\n",
       " ('fortnite', 12887),\n",
       " ('thishow', 12892),\n",
       " ('religius', 12900),\n",
       " ('wewigions', 12930),\n",
       " ('wowwd', 12931),\n",
       " ('thewe', 12932),\n",
       " ('fiwe', 12933),\n",
       " ('stawted', 12934),\n",
       " ('loksabha2019', 12974),\n",
       " ('coronavirusnannan', 12978),\n",
       " ('khatre', 12988),\n",
       " ('pakoda', 12989),\n",
       " ('exmuslim', 12997),\n",
       " ('nonpoliticalnannan', 13010),\n",
       " ('bookmyshow', 13017),\n",
       " ('bhaiyya', 13019),\n",
       " ('deletedhi', 13061),\n",
       " ('themthe', 13062),\n",
       " ('askaway', 13083),\n",
       " ('jyada', 13096),\n",
       " ('craspedotropis', 13107),\n",
       " ('triservices', 13112),\n",
       " ('biodigester', 13117),\n",
       " ('playgooglecom', 13125),\n",
       " ('openspotifycom', 13131),\n",
       " ('watchv', 13132),\n",
       " ('thelogicalindiancom', 13139),\n",
       " ('wwwjmiacin', 13140),\n",
       " ('hyperloop', 13150),\n",
       " ('winwin', 13156),\n",
       " ('gslvf05', 13157),\n",
       " ('antidefection', 13158),\n",
       " ('simulatenous', 13162),\n",
       " ('postindependence', 13164),\n",
       " ('webdev', 13171),\n",
       " ('tooi', 13180),\n",
       " ('wwwnewyorkercom', 13198),\n",
       " ('fiitjee', 13206),\n",
       " ('achhe', 13224),\n",
       " ('syntalk', 13227),\n",
       " ('moneycontrol', 13230),\n",
       " ('bschool', 13239),\n",
       " ('cuttingedge', 13241),\n",
       " ('image621x414', 13250),\n",
       " ('wwwinstamojocom', 13252),\n",
       " ('indianstartupslastweekbuymeabeer', 13253),\n",
       " ('refstore', 13254),\n",
       " ('juhapura', 13265),\n",
       " ('jun18', 13266),\n",
       " ('krna', 13272),\n",
       " ('karoge', 13274),\n",
       " ('atishi', 13292),\n",
       " ('antibjp', 13298),\n",
       " ('archit', 13299),\n",
       " ('snollygoster', 13303),\n",
       " ('covid19coronavirusuttarpradeshyogiadityanath165807520200321', 13305),\n",
       " ('karamveer', 13324),\n",
       " ('ramdevs', 13325),\n",
       " ('fxtopcom', 13329),\n",
       " ('vedl', 13335),\n",
       " ('harshalbotlast', 13344),\n",
       " ('upaii', 13351),\n",
       " ('2mbps', 13353),\n",
       " ('digitaldutta', 13359),\n",
       " ('parulkar', 13361),\n",
       " ('hoezaay', 13366),\n",
       " ('kaafi', 13368),\n",
       " ('besan', 13376),\n",
       " ('partyi', 13389),\n",
       " ('fakingnews', 13390),\n",
       " ('selfexplanatory', 13392),\n",
       " ('pmoindia', 13424),\n",
       " ('timepass', 13444),\n",
       " ('wwwtheatlanticcom', 13447),\n",
       " ('motherfucking', 13450),\n",
       " ('tinylettercom', 13455),\n",
       " ('nadani', 13474),\n",
       " ('201415', 13507),\n",
       " ('etcthe', 13520),\n",
       " ('olx', 13536),\n",
       " ('mumbaikar', 13571),\n",
       " ('news24tvchannel', 13572),\n",
       " ('tablighis', 13574),\n",
       " ('abpmajhatv', 13576),\n",
       " ('rajeshtope11', 13577),\n",
       " ('bangaloremirror', 13587),\n",
       " ('tv9marathi', 13589),\n",
       " ('wwwindiatvnewscom', 13602),\n",
       " ('lathicharge', 13607),\n",
       " ('bangaloremirrorindiatimescom', 13611),\n",
       " ('wwwncbinlmnihgov', 13624),\n",
       " ('medd', 13630),\n",
       " ('saans', 13632),\n",
       " ('nowedit', 13635),\n",
       " ('udhav', 13641),\n",
       " ('statehttps', 13645),\n",
       " ('sourcerssutm', 13657),\n",
       " ('mediumpublic', 13658),\n",
       " ('ithttps', 13668),\n",
       " ('wwwhuffingtonpostin', 13685),\n",
       " ('bollynumbers', 13691),\n",
       " ('gormint', 13696),\n",
       " ('mangaluru', 13705),\n",
       " ('epigiri', 13707),\n",
       " ('vidyakrishnan', 13714),\n",
       " ('usbased', 13715),\n",
       " ('indianorigin', 13719),\n",
       " ('ptistories', 13720),\n",
       " ('aapko', 13726),\n",
       " ('aayi', 13727),\n",
       " ('toohttps', 13730),\n",
       " ('padega', 13733),\n",
       " ('secy', 13735),\n",
       " ('drosten', 13736),\n",
       " ('yediyurappa', 13739),\n",
       " ('aliexpress', 13758),\n",
       " ('biotique', 13780),\n",
       " ('curefit', 13784),\n",
       " ('things1', 13807),\n",
       " ('shaheenbaghoff1', 13818),\n",
       " ('economypolitics', 13827),\n",
       " ('gadgetsndtvcom', 13835),\n",
       " ('themi', 13837),\n",
       " ('thiswhat', 13847),\n",
       " ('wwwnationalheraldindiacom', 13849),\n",
       " ('kyc', 13851),\n",
       " ('nasas', 13888),\n",
       " ('rahega', 13900),\n",
       " ('rsss', 13913),\n",
       " ('castebased', 13914),\n",
       " ('nsut', 13919),\n",
       " ('dikha', 13927),\n",
       " ('gigafiber', 13929),\n",
       " ('onei', 13965),\n",
       " ('likha', 13970),\n",
       " ('hatefilled', 13985),\n",
       " ('worldi', 13993),\n",
       " ('donts', 14025),\n",
       " ('indiaone', 14026),\n",
       " ('workfromhome', 14039),\n",
       " ('npci', 14040),\n",
       " ('indoeuropean', 14051),\n",
       " ('firstpostnannan', 14069),\n",
       " ('indiaif', 14079),\n",
       " ('writereaddata', 14082),\n",
       " ('timecom', 14091),\n",
       " ('shitload', 14095),\n",
       " ('karunga', 14097),\n",
       " ('aapka', 14098),\n",
       " ('realme', 14102),\n",
       " ('chowkidar', 14104),\n",
       " ('selfbelief', 14115),\n",
       " ('butthurt', 14147),\n",
       " ('journos', 14150),\n",
       " ('thatd', 14175),\n",
       " ('lulz', 14181),\n",
       " ('moneyandbanking', 14183),\n",
       " ('antimodi', 14190),\n",
       " ('subramanium', 14221),\n",
       " ('timebound', 14226),\n",
       " ('sr1sortnew', 14237),\n",
       " ('fcrfs94k', 14241),\n",
       " ('kerbal', 14244),\n",
       " ('doggos', 14250),\n",
       " ('kaanmasti', 14253),\n",
       " ('tpnational', 14264),\n",
       " ('201718', 14266),\n",
       " ('gujjus', 14275),\n",
       " ('dhppi', 14278),\n",
       " ('engpdf', 14287),\n",
       " ('statethe', 14301),\n",
       " ('grmd', 14305),\n",
       " ('wwwflickrcom', 14306),\n",
       " ('6v29x7f', 14307),\n",
       " ('humara', 14308),\n",
       " ('swach', 14311),\n",
       " ('sharmaji', 14321),\n",
       " ('nptel', 14328),\n",
       " ('yearsi', 14332),\n",
       " ('ghaywan', 14338),\n",
       " ('201314', 14353),\n",
       " ('sansadnicin', 14361),\n",
       " ('clickbaity', 14364),\n",
       " ('nsso', 14372),\n",
       " ('uppermiddle', 14374),\n",
       " ('pariksha', 14375),\n",
       " ('wwwnewsclickin', 14376),\n",
       " ('fiveyear', 14378),\n",
       " ('stepwell', 14381),\n",
       " ('wwwdowntoearthorgin', 14389),\n",
       " ('universitys', 14399),\n",
       " ('dataworldbankorg', 14401),\n",
       " ('saidhere', 14402),\n",
       " ('livemintjpg', 14404),\n",
       " ('livemintcom', 14405),\n",
       " ('06a', 14406),\n",
       " ('wwweconomistcom', 14409),\n",
       " ('fundingthe', 14411),\n",
       " ('numberone', 14412),\n",
       " ('oneoff', 14422),\n",
       " ('them1', 14441),\n",
       " ('bachega', 14444),\n",
       " ('jagah', 14445),\n",
       " ('bhajanpura', 14457),\n",
       " ('delhiburns', 14458),\n",
       " ('gokulpuri', 14459),\n",
       " ('livelawindia', 14461),\n",
       " ('chandbagh', 14462),\n",
       " ('shitstorm', 14469),\n",
       " ('ilfs', 14475),\n",
       " ('ayushmann', 14484),\n",
       " ('videoshow', 14485),\n",
       " ('india3', 14494),\n",
       " ('coliving', 14495),\n",
       " ('it3', 14502),\n",
       " ('bumrah', 14503),\n",
       " ('doklam', 14512),\n",
       " ('parrikar', 14513),\n",
       " ('jaitleys', 14522),\n",
       " ('exchangerate', 14523),\n",
       " ('wwwpolicypeepulcom', 14529),\n",
       " ('5year', 14534),\n",
       " ('emcure', 14535),\n",
       " ('indianwpiinflation564', 14539),\n",
       " ('indiancpi973', 14540),\n",
       " ('flipkarts', 14545),\n",
       " ('fintech', 14549),\n",
       " ('heremy', 14550),\n",
       " ('thewire', 14561),\n",
       " ('anganwadis', 14562),\n",
       " ('samesex', 14571),\n",
       " ('indiaplaza', 14576),\n",
       " ('vaitheek', 14577),\n",
       " ('ileague', 14580),\n",
       " ('this2', 14586),\n",
       " ('ubereats', 14587),\n",
       " ('kodali', 14591),\n",
       " ('lootera', 14593),\n",
       " ('pickyourtrail', 14594),\n",
       " ('incin', 14598),\n",
       " ('xpost', 14607),\n",
       " ('rehne', 14614),\n",
       " ('somebodys', 14617),\n",
       " ('refsr', 14627),\n",
       " ('tshirts', 14640),\n",
       " ('indiawhat', 14653),\n",
       " ('brigading', 14678),\n",
       " ('etcwhat', 14685),\n",
       " ('greasemonkey', 14687),\n",
       " ('desis', 14689),\n",
       " ('etcso', 14693),\n",
       " ('usif', 14706),\n",
       " ('following1', 14713),\n",
       " ('obgyn', 14724),\n",
       " ('csection', 14725),\n",
       " ('amazonin', 14728),\n",
       " ('jumlabaaz', 14732),\n",
       " ('khada', 14739),\n",
       " ('saalo', 14740),\n",
       " ('baaki', 14741),\n",
       " ('notebandi', 14756),\n",
       " ('dominar', 14758),\n",
       " ('lumpsum', 14811),\n",
       " ('498a', 14812),\n",
       " ('10monthold', 14833),\n",
       " ('wwwdawncom', 14838),\n",
       " ('tableeghi', 14839),\n",
       " ('covid19srchashtag', 14841),\n",
       " ('mombatti', 14850),\n",
       " ('mukeshmukeshs', 14853),\n",
       " ('sreenivasanjain', 14854),\n",
       " ('mumbaihttps', 14855),\n",
       " ('coronavirusoutbreak', 14857),\n",
       " ('selfproclaimed', 14864),\n",
       " ('drharshvardhan', 14876),\n",
       " ('rameshlaus', 14879),\n",
       " ('mayankbhagwat', 14885),\n",
       " ('wwwmedrxivorg', 14890),\n",
       " ('101101', 14891),\n",
       " ('wwwindiaspendcom', 14918),\n",
       " ('rajasthans', 14926),\n",
       " ('aprilhttps', 14928),\n",
       " ('yday', 14934),\n",
       " ...]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example words not present in the Glove embeddings\n",
    "title_n_body_n_comment_encoded[\"words_not_in_glove\"]\n",
    "\n",
    "#Most words are Hindi Words -> Appun, Bhaiya, etc.. , joined words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2764, 20)\n",
      "(2764, 150)\n",
      "(2764, 170)\n",
      "(2764, 370)\n",
      "(2764, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_title.shape)\n",
    "print(X_body.shape)\n",
    "print(X_title_n_body.shape)\n",
    "print(X_title_n_body_n_comment.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(num_words, em, max_sequence_length):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                embeddings_initializer=Constant(em),\n",
    "                                input_length=max_sequence_length,\n",
    "                                trainable=True)\n",
    "    input_text_ = Input(shape = (max_sequence_length,), dtype = 'int32')\n",
    "    embedded_sequences = embedding_layer(input_text_)\n",
    "    output_text_ = Dropout(0.2)(embedded_sequences)\n",
    "    output_text_ = Conv1D(64, 3, activation='relu')(output_text_)\n",
    "    output_text_ = MaxPooling1D(2)(output_text_)\n",
    "    output_text_ = Conv1D(100, 3, activation='relu')(output_text_)\n",
    "    output_text_ = MaxPooling1D(2)(output_text_)\n",
    "    output_text_ = Flatten()(output_text_)\n",
    "    output_text_ = Dense(12, activation='softmax')(output_text_)\n",
    "\n",
    "    model_text = Model(inputs = input_text_, outputs = output_text_)\n",
    "    print(model_text.summary())\n",
    "    return model_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_n_train(model, X_train, Y_train, X_test, Y_test, batch_size, epochs, optimizer = 'adam', save = 0, save_name = 'test'):\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, Y_test))\n",
    "    if(save):\n",
    "        model.save(f\"{save_name}.h5\")\n",
    "        print(\"MODEL SAVED AS {}\".format(save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and rain Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 20, 300)           2207400   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 18, 64)            57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 9, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 7, 100)            19300     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 3, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                3612      \n",
      "=================================================================\n",
      "Total params: 2,287,976\n",
      "Trainable params: 2,287,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2073 samples, validate on 691 samples\n",
      "Epoch 1/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.2729 - accuracy: 0.9178 - val_loss: 0.2466 - val_accuracy: 0.9209\n",
      "Epoch 2/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.2114 - accuracy: 0.9292 - val_loss: 0.1953 - val_accuracy: 0.9395\n",
      "Epoch 3/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.1547 - accuracy: 0.9473 - val_loss: 0.1814 - val_accuracy: 0.9407\n",
      "Epoch 4/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.1160 - accuracy: 0.9605 - val_loss: 0.1760 - val_accuracy: 0.9444\n",
      "Epoch 5/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.0890 - accuracy: 0.9709 - val_loss: 0.1797 - val_accuracy: 0.9433\n",
      "Epoch 6/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.0691 - accuracy: 0.9770 - val_loss: 0.1903 - val_accuracy: 0.9430\n",
      "Epoch 7/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.0547 - accuracy: 0.9819 - val_loss: 0.1923 - val_accuracy: 0.9445\n",
      "Epoch 8/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.0464 - accuracy: 0.9852 - val_loss: 0.2096 - val_accuracy: 0.9401\n",
      "Epoch 9/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.2110 - val_accuracy: 0.9397\n",
      "Epoch 10/10\n",
      "2073/2073 [==============================] - 3s 1ms/step - loss: 0.0413 - accuracy: 0.9879 - val_loss: 0.2195 - val_accuracy: 0.9387\n"
     ]
    }
   ],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(title_encoded[\"tokenizer\"].word_index) + 1)\n",
    "model = model_1(num_words, title_encoded[\"embedding_matrix\"], MAX_TITLE_LENGTH)\n",
    "\n",
    "# Train Test Split titles\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_title, Y, test_size=0.25, random_state=42)\n",
    "compile_n_train(model, X_train, Y_train, X_test, Y_test, 32, 10, save = 0, save_name='model2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^^^^^^^^^^^^^^^\n",
    "## With Only titles\n",
    "#### Classification Accuracy Model1 with inputs only title, for 10 epoch is \n",
    "#### Train_acc = 98.8 % , Val_acc = 93.77%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "#Check some Predictions\n",
    "Y_predicted_decoded = label_encoder.inverse_transform(predicted.argmax(axis = 1)[20:22])\n",
    "Y_test_decoded = label_encoder.inverse_transform(Y_test.argmax(axis = 1)[20:22])\n",
    "\n",
    "print(Y_predicted_decoded, Y_test_decoded)\n",
    "\n",
    "#Confusion Matrix\n",
    "classes = [label_decode(v) for v in [0,1,2,3,4,5,6,7,8,9,10,11]]\n",
    "print(classes)\n",
    "cm = metrics.confusion_matrix(Y_test.argmax(axis = 1), predicted.argmax(axis = 1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 170, 300)          12366900  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 170, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 168, 64)           57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 84, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 82, 100)           19300     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 41, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4100)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                49212     \n",
      "=================================================================\n",
      "Total params: 12,493,076\n",
      "Trainable params: 12,493,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2073 samples, validate on 691 samples\n",
      "Epoch 1/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.2769 - accuracy: 0.9168 - val_loss: 0.2615 - val_accuracy: 0.9173\n",
      "Epoch 2/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.2284 - accuracy: 0.9223 - val_loss: 0.2248 - val_accuracy: 0.9214\n",
      "Epoch 3/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.1581 - accuracy: 0.9426 - val_loss: 0.2062 - val_accuracy: 0.9329\n",
      "Epoch 4/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.1014 - accuracy: 0.9658 - val_loss: 0.2086 - val_accuracy: 0.9372\n",
      "Epoch 5/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 0.2107 - val_accuracy: 0.9362\n",
      "Epoch 6/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.0521 - accuracy: 0.9850 - val_loss: 0.2219 - val_accuracy: 0.9381\n",
      "Epoch 7/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.0429 - accuracy: 0.9886 - val_loss: 0.2117 - val_accuracy: 0.9438\n",
      "Epoch 8/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.0391 - accuracy: 0.9904 - val_loss: 0.2004 - val_accuracy: 0.9431\n",
      "Epoch 9/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.0293 - accuracy: 0.9927 - val_loss: 0.2181 - val_accuracy: 0.9445\n",
      "Epoch 10/10\n",
      "2073/2073 [==============================] - 16s 8ms/step - loss: 0.0283 - accuracy: 0.9930 - val_loss: 0.2033 - val_accuracy: 0.9436\n"
     ]
    }
   ],
   "source": [
    "# With Title and Body\n",
    "# Train Test Split titles and body\n",
    "num_words = min(MAX_NUM_WORDS, len(title_n_body_encoded[\"tokenizer\"].word_index) + 1)\n",
    "model = model_1(num_words, title_n_body_encoded[\"embedding_matrix\"], MAX_TITLE_LENGTH + MAX_BODY_LENGTH)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_title_n_body, Y, test_size=0.25, random_state=42)\n",
    "compile_n_train(model, X_train, Y_train, X_test, Y_test, 32, 10, save = 0, save_name='model2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With  titles and Body\n",
    "#### Classification Accuracy Model1 with inputs only title, for 10 epoch is \n",
    "#### Train_acc = 99.3 % , Val_acc = 94.36%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "#Check some Predictions\n",
    "Y_predicted_decoded = label_encoder.inverse_transform(predicted.argmax(axis = 1)[20:22])\n",
    "Y_test_decoded = label_encoder.inverse_transform(Y_test.argmax(axis = 1)[20:22])\n",
    "\n",
    "print(Y_predicted_decoded, Y_test_decoded)\n",
    "\n",
    "#Confusion Matrix\n",
    "classes = [label_decode(v) for v in [0,1,2,3,4,5,6,7,8,9,10,11]]\n",
    "print(classes)\n",
    "cm = metrics.confusion_matrix(Y_test.argmax(axis = 1), predicted.argmax(axis = 1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model 2  -- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2(num_words, em, max_sequence_length, with_dropout):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                    EMBEDDING_DIM,\n",
    "                                    embeddings_initializer=Constant(em),\n",
    "                                    input_length=max_sequence_length,\n",
    "                                    trainable=False)\n",
    "    input_text_ = Input(shape = (max_sequence_length,), dtype = 'int32')\n",
    "    embedded_sequences = embedding_layer(input_text_)\n",
    "    if(with_dropout):\n",
    "        output_text_ = Dropout(0.2)(embedded_sequences)\n",
    "        output_text_ = keras.layers.LSTM(max_sequence_length, activation='tanh')(output_text_)\n",
    "    else:\n",
    "        output_text_ = keras.layers.LSTM(max_sequence_length, activation='tanh')(embedded_sequences)\n",
    "    if(with_dropout):\n",
    "        output_text_ = Dropout(0.2)(output_text_)\n",
    "    output_text_ = keras.layers.Dense(12, activation='softmax')(output_text_)\n",
    "    model = Model(inputs = input_text_, outputs = output_text_)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save model With DROPOUT with Only Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_18 (Embedding)     (None, 20, 300)           2207400   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 20, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 20)                25680     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 12)                252       \n",
      "=================================================================\n",
      "Total params: 2,233,332\n",
      "Trainable params: 25,932\n",
      "Non-trainable params: 2,207,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2073 samples, validate on 691 samples\n",
      "Epoch 1/10\n",
      "2073/2073 [==============================] - 1s 651us/step - loss: 0.2763 - accuracy: 0.9167 - val_loss: 0.2574 - val_accuracy: 0.9167\n",
      "Epoch 2/10\n",
      "2073/2073 [==============================] - 1s 337us/step - loss: 0.2374 - accuracy: 0.9184 - val_loss: 0.2115 - val_accuracy: 0.9252\n",
      "Epoch 3/10\n",
      "2073/2073 [==============================] - 1s 354us/step - loss: 0.2001 - accuracy: 0.9286 - val_loss: 0.1823 - val_accuracy: 0.9363\n",
      "Epoch 4/10\n",
      "2073/2073 [==============================] - 1s 323us/step - loss: 0.1772 - accuracy: 0.9390 - val_loss: 0.1662 - val_accuracy: 0.9440\n",
      "Epoch 5/10\n",
      "2073/2073 [==============================] - 1s 371us/step - loss: 0.1604 - accuracy: 0.9460 - val_loss: 0.1561 - val_accuracy: 0.9480\n",
      "Epoch 6/10\n",
      "2073/2073 [==============================] - 1s 337us/step - loss: 0.1461 - accuracy: 0.9522 - val_loss: 0.1470 - val_accuracy: 0.9528\n",
      "Epoch 7/10\n",
      "2073/2073 [==============================] - 1s 335us/step - loss: 0.1363 - accuracy: 0.9548 - val_loss: 0.1432 - val_accuracy: 0.9547\n",
      "Epoch 8/10\n",
      "2073/2073 [==============================] - 1s 336us/step - loss: 0.1268 - accuracy: 0.9579 - val_loss: 0.1403 - val_accuracy: 0.9545\n",
      "Epoch 9/10\n",
      "2073/2073 [==============================] - 1s 371us/step - loss: 0.1212 - accuracy: 0.9602 - val_loss: 0.1380 - val_accuracy: 0.9553\n",
      "Epoch 10/10\n",
      "2073/2073 [==============================] - 1s 320us/step - loss: 0.1172 - accuracy: 0.9607 - val_loss: 0.1368 - val_accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(title_encoded[\"tokenizer\"].word_index) + 1)\n",
    "model = model_2(num_words, title_encoded[\"embedding_matrix\"], MAX_TITLE_LENGTH, with_dropout=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_title, Y, test_size=0.25, random_state=42)\n",
    "compile_n_train(model, X_train, Y_train, X_test, Y_test, 32, 10, save = 1, save_name='final_model') \n",
    "######################### SAVING THE MODEL h5 file as the final_model.h5  ########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Accuracy Model2 with inputs only title, for 10 epoch is \n",
    "#### Train_acc = 96.08 % , Val_acc = 95.71%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Food' 'Coronavirus'] ['Food' 'Coronavirus']\n",
      "['AskIndia', 'Coronavirus', 'Non-Political', 'Scheduled', 'Photography', 'Science/Technology', 'Politics', 'Business/Finance', 'Policy/Economy', 'Sports', 'Food', 'AMA']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[46,  0,  1,  0,  0,  0,  0,  0,  0,  2,  0,  1],\n",
       "       [ 0, 24,  6,  2,  5,  0,  2,  5,  1,  3,  4,  4],\n",
       "       [ 0,  9, 26,  0,  1,  1,  2, 11,  2,  2,  3,  1],\n",
       "       [ 0,  1,  0, 67,  1,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  3,  0,  4, 50,  0,  1,  1,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0, 51,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  2,  0,  0,  0, 37,  0,  1,  2,  3,  0],\n",
       "       [ 0,  9,  6,  1,  2,  2,  1, 27,  7,  0,  1,  1],\n",
       "       [ 0,  4,  2,  4,  3,  3,  0,  9, 38,  2,  1,  0],\n",
       "       [ 0,  6,  4,  0,  1,  0,  3,  3,  2, 27,  4,  0],\n",
       "       [ 0,  5, 16,  2,  0,  0,  2,  2,  1,  2, 32,  2],\n",
       "       [ 1,  2,  2,  1,  0,  1,  3,  3,  3,  3,  0, 38]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "#Check some Predictions\n",
    "Y_predicted_decoded = label_encoder.inverse_transform(predicted.argmax(axis = 1)[20:22])\n",
    "Y_test_decoded = label_encoder.inverse_transform(Y_test.argmax(axis = 1)[20:22])\n",
    "\n",
    "print(Y_predicted_decoded, Y_test_decoded)\n",
    "\n",
    "#Confusion Matrix\n",
    "classes = [label_decode(v) for v in [0,1,2,3,4,5,6,7,8,9,10,11]]\n",
    "print(classes)\n",
    "cm = metrics.confusion_matrix(Y_test.argmax(axis = 1), predicted.argmax(axis = 1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save model With DROPOUT with Title and Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding_19 (Embedding)     (None, 170, 300)          12366900  \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 170, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 170)               320280    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 12)                2052      \n",
      "=================================================================\n",
      "Total params: 12,689,232\n",
      "Trainable params: 322,332\n",
      "Non-trainable params: 12,366,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2073 samples, validate on 691 samples\n",
      "Epoch 1/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.2448 - accuracy: 0.9208 - val_loss: 0.2017 - val_accuracy: 0.9302\n",
      "Epoch 2/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.1830 - accuracy: 0.9362 - val_loss: 0.1798 - val_accuracy: 0.9387\n",
      "Epoch 3/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.1521 - accuracy: 0.9471 - val_loss: 0.1560 - val_accuracy: 0.9460\n",
      "Epoch 4/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.1357 - accuracy: 0.9511 - val_loss: 0.1706 - val_accuracy: 0.9418\n",
      "Epoch 5/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.1265 - accuracy: 0.9559 - val_loss: 0.1546 - val_accuracy: 0.9479\n",
      "Epoch 6/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.1207 - accuracy: 0.9582 - val_loss: 0.1596 - val_accuracy: 0.9456\n",
      "Epoch 7/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.1028 - accuracy: 0.9632 - val_loss: 0.1516 - val_accuracy: 0.9498\n",
      "Epoch 8/10\n",
      "2073/2073 [==============================] - 20s 10ms/step - loss: 0.0941 - accuracy: 0.9670 - val_loss: 0.1595 - val_accuracy: 0.9463\n",
      "Epoch 9/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.0876 - accuracy: 0.9691 - val_loss: 0.1549 - val_accuracy: 0.9487\n",
      "Epoch 10/10\n",
      "2073/2073 [==============================] - 19s 9ms/step - loss: 0.0914 - accuracy: 0.9681 - val_loss: 0.1608 - val_accuracy: 0.9457\n"
     ]
    }
   ],
   "source": [
    "# With Title and Body\n",
    "# Train Test Split titles and body\n",
    "num_words = min(MAX_NUM_WORDS, len(title_n_body_encoded[\"tokenizer\"].word_index) + 1)\n",
    "model = model_2(num_words, title_n_body_encoded[\"embedding_matrix\"], MAX_TITLE_LENGTH + MAX_BODY_LENGTH, with_dropout=1)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_title_n_body, Y, test_size=0.25, random_state=42)\n",
    "compile_n_train(model, X_train, Y_train, X_test, Y_test, 32, 10, save = 0, save_name='model_lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Accuracy Model2 with inputs  title and Body, for 10 epoch is \n",
    "#### Train_acc = 95.50 % , Val_acc = 94.56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AskIndia' 'Coronavirus'] ['Food' 'Coronavirus']\n",
      "['AskIndia', 'Coronavirus', 'Non-Political', 'Scheduled', 'Photography', 'Science/Technology', 'Politics', 'Business/Finance', 'Policy/Economy', 'Sports', 'Food', 'AMA']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31,  4,  1,  0,  0,  0,  0,  0,  1,  2,  7,  4],\n",
       "       [ 4, 28,  0,  3,  0,  1,  0,  4,  1,  4,  4,  7],\n",
       "       [ 1,  6, 26,  0,  0,  1,  0, 13,  1,  1,  9,  0],\n",
       "       [ 1,  3,  1, 59,  1,  0,  0,  1,  4,  0,  0,  0],\n",
       "       [ 6, 14,  2,  4, 26,  0,  0,  0,  1,  3,  4,  0],\n",
       "       [ 2,  5,  0,  0,  0, 41,  0,  1,  1,  1,  1,  0],\n",
       "       [ 1,  8,  0,  1,  0,  0, 29,  0,  0,  1,  8,  3],\n",
       "       [ 1,  4, 12,  0,  0,  0,  0, 28,  6,  1,  5,  0],\n",
       "       [ 8,  4,  0,  3,  0,  1,  0,  5, 34,  2,  6,  3],\n",
       "       [ 1,  7,  2,  1,  0,  1,  2,  2,  1, 27,  4,  2],\n",
       "       [ 1,  5,  2,  3,  0,  1,  0,  2,  4,  1, 42,  3],\n",
       "       [ 3,  1,  3,  1,  0,  0,  0,  0,  2,  2,  3, 42]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "#Check some Predictions\n",
    "Y_predicted_decoded = label_encoder.inverse_transform(predicted.argmax(axis = 1)[20:22])\n",
    "Y_test_decoded = label_encoder.inverse_transform(Y_test.argmax(axis = 1)[20:22])\n",
    "\n",
    "print(Y_predicted_decoded, Y_test_decoded)\n",
    "\n",
    "#Confusion Matrix\n",
    "classes = [label_decode(v) for v in [0,1,2,3,4,5,6,7,8,9,10,11]]\n",
    "print(classes)\n",
    "cm = metrics.confusion_matrix(Y_test.argmax(axis = 1), predicted.argmax(axis = 1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model3  --- Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional\n",
    "def model_3(num_words, em, max_sequence_length, with_dropout):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                    EMBEDDING_DIM,\n",
    "                                    embeddings_initializer=Constant(em),\n",
    "                                    input_length=max_sequence_length,\n",
    "                                    trainable=False)\n",
    "    input_text_ = Input(shape = (max_sequence_length,), dtype = 'int32')\n",
    "    embedded_sequences = embedding_layer(input_text_)\n",
    "    if(with_dropout):\n",
    "        output_text_ = Dropout(0.2)(embedded_sequences)\n",
    "        output_text = Bidirectional(keras.layers.LSTM(max_sequence_length, return_sequences = True))(output_text_)\n",
    "    else:\n",
    "        output_text = Bidirectional(keras.layers.LSTM(max_sequence_length, return_sequences = True))(embedded_sequences)\n",
    "    output_text = Bidirectional(keras.layers.LSTM(max_sequence_length, return_sequences = False))(output_text)\n",
    "    output_text = Dense(12)(output_text)\n",
    "    model = Model(inputs = input_text_, outputs = output_text)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save model With DROPOUT with Only Title Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_17 (Embedding)     (None, 20, 300)           2207400   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 20, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 20, 40)            51360     \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 40)                9760      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                492       \n",
      "=================================================================\n",
      "Total params: 2,269,012\n",
      "Trainable params: 61,612\n",
      "Non-trainable params: 2,207,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2073 samples, validate on 691 samples\n",
      "Epoch 1/10\n",
      "2073/2073 [==============================] - 3s 2ms/step - loss: 0.4828 - accuracy: 0.9167 - val_loss: 0.3067 - val_accuracy: 0.9167\n",
      "Epoch 2/10\n",
      "2073/2073 [==============================] - 2s 824us/step - loss: 0.2968 - accuracy: 0.9167 - val_loss: 0.2780 - val_accuracy: 0.9167\n",
      "Epoch 3/10\n",
      "2073/2073 [==============================] - 2s 766us/step - loss: 0.2809 - accuracy: 0.9169 - val_loss: 0.2728 - val_accuracy: 0.9168\n",
      "Epoch 4/10\n",
      "2073/2073 [==============================] - 2s 777us/step - loss: 0.2690 - accuracy: 0.9169 - val_loss: 0.2605 - val_accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "2073/2073 [==============================] - 2s 767us/step - loss: 0.2498 - accuracy: 0.9172 - val_loss: 0.2523 - val_accuracy: 0.9169\n",
      "Epoch 6/10\n",
      "2073/2073 [==============================] - 2s 786us/step - loss: 0.2479 - accuracy: 0.9176 - val_loss: 0.2618 - val_accuracy: 0.9200\n",
      "Epoch 7/10\n",
      "2073/2073 [==============================] - 2s 770us/step - loss: 0.2364 - accuracy: 0.9195 - val_loss: 0.2374 - val_accuracy: 0.9208\n",
      "Epoch 8/10\n",
      "2073/2073 [==============================] - 2s 773us/step - loss: 0.2250 - accuracy: 0.9203 - val_loss: 0.2449 - val_accuracy: 0.9231\n",
      "Epoch 9/10\n",
      "2073/2073 [==============================] - 2s 777us/step - loss: 0.2182 - accuracy: 0.9231 - val_loss: 0.2362 - val_accuracy: 0.9249\n",
      "Epoch 10/10\n",
      "2073/2073 [==============================] - 2s 771us/step - loss: 0.2084 - accuracy: 0.9245 - val_loss: 0.2291 - val_accuracy: 0.9264\n"
     ]
    }
   ],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(title_encoded[\"tokenizer\"].word_index) + 1)\n",
    "model = model_3(num_words, title_encoded[\"embedding_matrix\"], MAX_TITLE_LENGTH, with_dropout=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_title, Y, test_size=0.25, random_state=42)\n",
    "compile_n_train(model, X_train, Y_train, X_test, Y_test, 32, 10, save = 0, save_name='model_BiLSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Accuracy Model3 with inputs  title , for 10 epoch is \n",
    "#### Train_acc = 91.67 % , Val_acc = 91.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "#Check some Predictions\n",
    "Y_predicted_decoded = label_encoder.inverse_transform(predicted.argmax(axis = 1)[20:22])\n",
    "Y_test_decoded = label_encoder.inverse_transform(Y_test.argmax(axis = 1)[20:22])\n",
    "\n",
    "print(Y_predicted_decoded, Y_test_decoded)\n",
    "\n",
    "#Confusion Matrix\n",
    "classes = [label_decode(v) for v in [0,1,2,3,4,5,6,7,8,9,10,11]]\n",
    "print(classes)\n",
    "cm = metrics.confusion_matrix(Y_test.argmax(axis = 1), predicted.argmax(axis = 1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save model With DROPOUT with Title and Body Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 170, 300)          12366900  \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 170, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 170, 340)          640560    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 340)               694960    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 12)                4092      \n",
      "=================================================================\n",
      "Total params: 13,706,512\n",
      "Trainable params: 1,339,612\n",
      "Non-trainable params: 12,366,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2073 samples, validate on 691 samples\n",
      "Epoch 1/10\n",
      "2073/2073 [==============================] - 72s 35ms/step - loss: 0.4222 - accuracy: 0.9052 - val_loss: 0.4217 - val_accuracy: 0.9152\n",
      "Epoch 2/10\n",
      "2073/2073 [==============================] - 72s 35ms/step - loss: 0.3588 - accuracy: 0.9098 - val_loss: 0.3767 - val_accuracy: 0.9137\n",
      "Epoch 3/10\n",
      "2073/2073 [==============================] - 72s 35ms/step - loss: 0.3284 - accuracy: 0.9149 - val_loss: 0.8640 - val_accuracy: 0.8673\n",
      "Epoch 4/10\n",
      "2073/2073 [==============================] - 73s 35ms/step - loss: 0.4219 - accuracy: 0.8969 - val_loss: 0.3365 - val_accuracy: 0.9156\n",
      "Epoch 5/10\n",
      "2073/2073 [==============================] - 80s 39ms/step - loss: 0.2933 - accuracy: 0.9114 - val_loss: 0.3525 - val_accuracy: 0.9094\n",
      "Epoch 6/10\n",
      "2073/2073 [==============================] - 85s 41ms/step - loss: 0.2653 - accuracy: 0.9142 - val_loss: 0.3272 - val_accuracy: 0.9137\n",
      "Epoch 7/10\n",
      "2073/2073 [==============================] - 87s 42ms/step - loss: 0.3962 - accuracy: 0.8763 - val_loss: 0.5025 - val_accuracy: 0.8491\n",
      "Epoch 8/10\n",
      "2073/2073 [==============================] - 88s 42ms/step - loss: 0.3677 - accuracy: 0.8927 - val_loss: 0.4684 - val_accuracy: 0.8705\n",
      "Epoch 9/10\n",
      "2073/2073 [==============================] - 92s 44ms/step - loss: 0.7825 - accuracy: 0.8553 - val_loss: 1.1142 - val_accuracy: 0.7601\n",
      "Epoch 10/10\n",
      "2073/2073 [==============================] - 89s 43ms/step - loss: 0.9008 - accuracy: 0.7245 - val_loss: 0.6698 - val_accuracy: 0.7745\n"
     ]
    }
   ],
   "source": [
    "# With Title and Body\n",
    "# Train Test Split titles and body\n",
    "num_words = min(MAX_NUM_WORDS, len(title_n_body_encoded[\"tokenizer\"].word_index) + 1)\n",
    "model = model_3(num_words, title_n_body_encoded[\"embedding_matrix\"], MAX_TITLE_LENGTH + MAX_BODY_LENGTH, with_dropout=1)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_title_n_body, Y, test_size=0.25, random_state=42)\n",
    "compile_n_train(model, X_train, Y_train, X_test, Y_test, 32, 10, save = 0, save_name='model_BiLstm_tnb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Accuracy Model3 with inputs  title and Body, for 10 epoch is \n",
    "#### Train_acc = 90.08 % , Val_acc = 77.45%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports' 'Coronavirus'] ['Food' 'Coronavirus']\n",
      "['AskIndia', 'Coronavirus', 'Non-Political', 'Scheduled', 'Photography', 'Science/Technology', 'Politics', 'Business/Finance', 'Policy/Economy', 'Sports', 'Food', 'AMA']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12,  2,  1,  0,  6,  1,  0,  0,  4,  0, 13, 11],\n",
       "       [ 6,  2,  0,  2,  5,  6,  1,  2,  5,  1, 11, 15],\n",
       "       [ 1,  0,  3,  1,  1,  0,  1,  0,  3,  1,  6, 41],\n",
       "       [ 2,  0,  2, 50,  2,  0,  0,  0, 10,  0,  1,  3],\n",
       "       [ 3,  0,  0,  3, 34,  3,  0,  0,  4,  2,  2,  9],\n",
       "       [ 2,  0,  2,  2,  9, 10,  0,  1, 10,  0, 10,  6],\n",
       "       [ 1,  2,  0,  1,  4,  3, 21,  1,  5,  0,  6,  7],\n",
       "       [ 1,  0,  5,  2,  4,  2,  0,  1,  5,  0,  9, 28],\n",
       "       [ 1,  0,  2,  7, 12,  4,  0,  0,  9,  0, 14, 17],\n",
       "       [ 4,  0,  4,  0, 12,  0,  2,  0,  2,  1, 11, 14],\n",
       "       [ 1,  1,  2,  1,  0,  0,  0,  0,  7,  0, 26, 26],\n",
       "       [ 0,  2,  2,  1,  1,  0,  0,  0,  5,  0, 12, 34]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "#Check some Predictions\n",
    "Y_predicted_decoded = label_encoder.inverse_transform(predicted.argmax(axis = 1)[20:22])\n",
    "Y_test_decoded = label_encoder.inverse_transform(Y_test.argmax(axis = 1)[20:22])\n",
    "\n",
    "print(Y_predicted_decoded, Y_test_decoded)\n",
    "\n",
    "#Confusion Matrix\n",
    "classes = [label_decode(v) for v in [0,1,2,3,4,5,6,7,8,9,10,11]]\n",
    "print(classes)\n",
    "cm = metrics.confusion_matrix(Y_test.argmax(axis = 1), predicted.argmax(axis = 1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. So we are able to see that models with only Title Data and Title Data with <br> Body, Both are working almost the same, So using body is just being redundant <br>. So in the final model, only titles will be used for predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We can see that the model with single layer LSTM is working better than all the models. Its accuracies are Train_acc = 96.08 % , Val_acc = 95.71%. Hence the model (using dropout) seems to have no overfitting and less bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Here since we are using LSTM, the model is able to capture long term dependencies, i.e it is capable of remembering words that occur previously. \n",
    "## Bidirectional not working in this case may be due to non requirement of remembering from both sides, and thus creating a redundancy and complexity in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hence we can say that our Model 2, is good at capturing the meaning of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
